{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handling_Categorical Variables.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMt/sdqxCxNxiW7VvM6aAil",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyansh1195/Kaggle-ML-Exercise-Notebooks/blob/master/Handling_Categorical_Variables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBXnlHTkO-to",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "14b21e25-80f1-4baa-d05d-ddff5dfb1e61"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "X = pd.read_csv('train.csv', index_col='Id')\n",
        "#test_data = pd.read_csv('test.csv', index_col='Id')\n",
        "#print(X)\n",
        "#print(test_data)\n",
        "\n",
        "# Remove rows with missing target values\n",
        "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
        "#axis=0 or, 'index' drops rows with missing values, axis=1 or, 'columns'drops columns which contain missing value\n",
        "#subset label along which you wish to drop\n",
        "\n",
        "#define y after removing missing values\n",
        "y = X.SalePrice\n",
        "print(y)\n",
        "\n",
        "#separate target from predictors\n",
        "#here, separate SalePrice from reamining columns\n",
        "X.drop(['SalePrice'], axis=1, inplace=True)\n",
        "#SalePrice column removed from X\n",
        "\n",
        "print(X)\n",
        "#print(test)\n",
        "\n",
        "# To keep things simple, we'll drop columns with missing values\n",
        "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
        "X.drop(cols_with_missing, axis=1, inplace=True)\n",
        "\n",
        "# Break off test set from training data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
        "                                                      random_state=0)\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Function for comparing different approaches\n",
        "def score_dataset(X_train, X_test, y_train, y_test):\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    return mean_absolute_error(y_test, preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Id\n",
            "1       208500\n",
            "2       181500\n",
            "3       223500\n",
            "4       140000\n",
            "5       250000\n",
            "         ...  \n",
            "1456    175000\n",
            "1457    210000\n",
            "1458    266500\n",
            "1459    142125\n",
            "1460    147500\n",
            "Name: SalePrice, Length: 1460, dtype: int64\n",
            "      MSSubClass MSZoning  LotFrontage  ...  YrSold SaleType SaleCondition\n",
            "Id                                      ...                               \n",
            "1             60       RL         65.0  ...    2008       WD        Normal\n",
            "2             20       RL         80.0  ...    2007       WD        Normal\n",
            "3             60       RL         68.0  ...    2008       WD        Normal\n",
            "4             70       RL         60.0  ...    2006       WD       Abnorml\n",
            "5             60       RL         84.0  ...    2008       WD        Normal\n",
            "...          ...      ...          ...  ...     ...      ...           ...\n",
            "1456          60       RL         62.0  ...    2007       WD        Normal\n",
            "1457          20       RL         85.0  ...    2010       WD        Normal\n",
            "1458          70       RL         66.0  ...    2010       WD        Normal\n",
            "1459          20       RL         68.0  ...    2010       WD        Normal\n",
            "1460          20       RL         75.0  ...    2008       WD        Normal\n",
            "\n",
            "[1460 rows x 79 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diUwc0jXLt_x",
        "colab_type": "text"
      },
      "source": [
        "**Categorical Variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggDLIMF0S8wJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#label encoding assumes an ordering of categories whereas one hot encoding does not.\n",
        "#eg-This approach assumes an ordering of the categories: \"Never\" (0) < \"Rarely\" (1) < \"Most days\" (2) < \"Every day\" (3)\n",
        "#Colors:Red, Yellow , Green doesn't assume an ordering of categories."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aag-zwFdRv5j",
        "colab_type": "text"
      },
      "source": [
        "Drop columns with categorical **This approach is wrong!!!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0zoWbi_Tnnf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "96faa4bb-8b6c-44f4-a30b-4c0e5f723d98"
      },
      "source": [
        "# '.index' provides the index of the columns\n",
        "#Drop columns with categorical data\n",
        "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
        "drop_X_test = X_test.select_dtypes(exclude=['object'])\n",
        "\n",
        "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
        "print(score_dataset(drop_X_train, drop_X_test, y_train, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE from Approach 1 (Drop categorical variables):\n",
            "17837.82570776256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLRNwZrZRp6B",
        "colab_type": "text"
      },
      "source": [
        "Label encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npE9lbCNRsXq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "651fe055-999e-4c63-a585-8057d24dd8f0"
      },
      "source": [
        "#print the unique entries in both the training and test sets\n",
        "print(\"Unique values in 'Condition2' column in training data:\", X_train.Condition2.unique())\n",
        "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_test.Condition2.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique values in 'Condition2' column in training data: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n",
            "\n",
            "Unique values in 'Condition2' column in validation data: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2bCUdSESSV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "122d500c-ebca-4531-adb4-f70c6a30e5c4"
      },
      "source": [
        "#drop the problematic categorical columns.\n",
        "# All categorical columns\n",
        "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
        "\n",
        "# Columns that can be safely label encoded\n",
        "good_label_cols = [col for col in object_cols if \n",
        "                   set(X_train[col]) == set(X_test[col])]\n",
        "        \n",
        "# Problematic columns that will be dropped from the dataset\n",
        "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
        "        \n",
        "print('Categorical columns that will be label encoded:', good_label_cols)\n",
        "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Categorical columns that will be label encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'LotConfig', 'BldgType', 'HouseStyle', 'ExterQual', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleCondition']\n",
            "\n",
            "Categorical columns that will be dropped from the dataset: ['Neighborhood', 'LandSlope', 'Exterior1st', 'Condition2', 'Foundation', 'Heating', 'SaleType', 'Functional', 'RoofStyle', 'ExterCond', 'Utilities', 'RoofMatl', 'Condition1', 'HeatingQC', 'Exterior2nd']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrH8wBThGk4o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c527943d-1b24-4eb4-9289-8fc80ad08fba"
      },
      "source": [
        "#label encoding to X_train and X_test\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Drop categorical columns that will not be encoded\n",
        "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
        "label_X_test = X_test.drop(bad_label_cols, axis=1)\n",
        "\n",
        "# Apply label encoder \n",
        "# Your code here\n",
        "label_encoder = LabelEncoder()\n",
        "for col in good_label_cols:\n",
        "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
        "    label_X_test[col] = label_encoder.transform(X_test[col])\n",
        "print(\"MAE from Approach 2 (Label Encoding):\") \n",
        "print(score_dataset(label_X_train, label_X_test, y_train, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE from Approach 2 (Label Encoding):\n",
            "17575.291883561644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcwxDGYHJpi7",
        "colab_type": "text"
      },
      "source": [
        "So far, we've tried two different approaches to dealing with categorical variables. And, we've seen that encoding categorical data yields better results than removing columns from the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thFI9oKHKU-I",
        "colab_type": "text"
      },
      "source": [
        "**Investigating cardinality**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmwvDTKTKUQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "ae528994-8d4d-4e8f-f9c3-0eb892f5c2bc"
      },
      "source": [
        "# Get number of unique entries in each column with categorical data\n",
        "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
        "d = dict(zip(object_cols, object_nunique))\n",
        "\n",
        "# Print number of unique entries by column, in ascending order\n",
        "sorted(d.items(), key=lambda x: x[1])\n",
        "#key=lambda x: x[1] used for list sorting\n",
        "#.items() method is used to return the list with all dictionary keys with values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Street', 2),\n",
              " ('Utilities', 2),\n",
              " ('CentralAir', 2),\n",
              " ('LandSlope', 3),\n",
              " ('PavedDrive', 3),\n",
              " ('LotShape', 4),\n",
              " ('LandContour', 4),\n",
              " ('ExterQual', 4),\n",
              " ('KitchenQual', 4),\n",
              " ('MSZoning', 5),\n",
              " ('LotConfig', 5),\n",
              " ('BldgType', 5),\n",
              " ('ExterCond', 5),\n",
              " ('HeatingQC', 5),\n",
              " ('Condition2', 6),\n",
              " ('RoofStyle', 6),\n",
              " ('Foundation', 6),\n",
              " ('Heating', 6),\n",
              " ('Functional', 6),\n",
              " ('SaleCondition', 6),\n",
              " ('RoofMatl', 7),\n",
              " ('HouseStyle', 8),\n",
              " ('Condition1', 9),\n",
              " ('SaleType', 9),\n",
              " ('Exterior1st', 15),\n",
              " ('Exterior2nd', 16),\n",
              " ('Neighborhood', 25)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR5peppNM_Wr",
        "colab_type": "text"
      },
      "source": [
        "The output above shows, for each column with categorical data, the number of unique values in the column. For instance, the 'Street' column in the training data has two unique values: 'Grvl' and 'Pave', corresponding to a gravel road and a paved road, respectively.\n",
        "\n",
        "We refer to the number of unique entries of a categorical variable as the cardinality of that categorical variable. For instance, the 'Street' variable has cardinality 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX_ulsiaJtdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EXAMPLE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7HxA2YuOPPv",
        "colab_type": "text"
      },
      "source": [
        "For large datasets with many rows, one-hot encoding can greatly expand the size of the dataset. For this reason, we typically will only one-hot encode columns with relatively low cardinality. Then, high cardinality columns can either be dropped from the dataset, or we can use label encoding.\n",
        "\n",
        "As an example, consider a dataset with 10,000 rows, and containing one categorical column with 100 unique entries.\n",
        "\n",
        "If this column is replaced with the corresponding one-hot encoding, how many entries are added to the dataset?\n",
        "If we instead replace the column with the label encoding, how many entries are added?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmLH4KADOUVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#How many entries are added to the dataset by \n",
        "# replacing the column with a one-hot encoding?\n",
        "#OH_entries_added = 1e4*100-1e4\n",
        "\n",
        "#How many entries are added to the dataset by\n",
        "# replacing the column with a label encoding?\n",
        "label_entries_added = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5yBk0c-OiZL",
        "colab_type": "text"
      },
      "source": [
        "**One Hot Encoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6EvFxjOsLa",
        "colab_type": "text"
      },
      "source": [
        "only create a one-hot encoding for columns with cardinality less than 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGlUnMOvOgDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e1b7183c-bbc4-4d96-bac2-242b66249e60"
      },
      "source": [
        "# Columns that will be one-hot encoded\n",
        "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
        "\n",
        "# Columns that will be dropped from the dataset\n",
        "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
        "\n",
        "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
        "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Categorical columns that will be one-hot encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
            "\n",
            "Categorical columns that will be dropped from the dataset: ['Neighborhood', 'Exterior1st', 'Exterior2nd']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFGCGmfcPBpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f086231e-a967-4c03-b40f-0ef4f1df1959"
      },
      "source": [
        "# Apply one-hot encoder to each column with categorical data\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
        "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
        "\n",
        "# One-hot encoding removed index; put it back\n",
        "OH_cols_train.index = X_train.index\n",
        "OH_cols_test.index = X_test.index\n",
        "\n",
        "# Remove categorical columns (will replace with one-hot encoding)\n",
        "num_X_train = X_train.drop(object_cols, axis=1)\n",
        "num_X_test = X_test.drop(object_cols, axis=1)\n",
        "\n",
        "# Add one-hot encoded columns to numerical features\n",
        "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
        "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
        "\n",
        "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
        "print(score_dataset(OH_X_train, OH_X_test, y_train, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE from Approach 3 (One-Hot Encoding):\n",
            "17525.345719178084\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}